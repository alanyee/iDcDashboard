{
 "metadata": {
  "name": "",
  "signature": "sha256:af5d00c40f6b6b432769866d6dea2140c963c8f9fdb49dbf894efee27366ca81"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Weather Analysis Using DC.js\n",
      "\n",
      "Here we want to analyze the weather dataset from NOAA.  Professor Freund has provided a sampled version of the data for initial analysis.  \n",
      "\n",
      "##Loading Data Into Pandas"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "\n",
      "import re\n",
      "print 'pandas version: ',pd.__version__\n",
      "print 'numpy version:',np.__version__\n",
      "print 'sklearn version:',sk.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we specify the location of the data provided by professor freund.  Need to insert links to download this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weather_file = \"/Users/dlisuk/Dropbox/UCSD/2014_FALL/DSE200_TA/DSE200/data/weather/SAMPLE_TMAX.csv\"\n",
      "stations_file = \"/Users/dlisuk/Dropbox/UCSD/2014_FALL/DSE200_TA/DSE200/data/weather/ghcnd-stations.txt\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we load the measurement data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "header=['station','measurement','year']+range(1,366)\n",
      "# D=pandas.DataFrame(columns=header)\n",
      "Data = pd.read_csv(weather_file,header=None,names=header)\n",
      "G=Data.ix[:,1:365]\n",
      "G[G<-400]=nan\n",
      "G[G>500]=nan\n",
      "G=G/10\n",
      "Data.ix[:,1:365]=G\n",
      "G=G.transpose()\n",
      "Data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we clean and load the stations list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make all lines be of length 90 to solve problem wilth read_fwf\n",
      "out=open('./ghcnd-stations_buffered.txt','w')\n",
      "for line in open(stations_file,'r').readlines():\n",
      "    line=line.rstrip()\n",
      "    string=line+' '*(90-len(line))+'\\n'\n",
      "    out.write(string)\n",
      "out.close()\n",
      "colspecs = [(0, 11), (11, 21), (21, 31), (31, 38),(38,41), (0,2)]\n",
      "stations = pd.read_fwf('./ghcnd-stations_buffered.txt', colspecs=colspecs, header=None, index_col=0,\n",
      "                       names=['latitude','longitude','elevation','state', 'country'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Join stations and measurement data and subset to just the US data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Djoined=Data.join(stations,on='station')\n",
      "Djoined = Djoined[Djoined.country == \"US\"]\n",
      "Djoined.country.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "##Plotting Weather Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('../')\n",
      "\n",
      "import dc_dashboard\n",
      "from dc_dashboard import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "DC.js doesn't support time series data which is wide.  Instead we must melt the data so that each row contains one measurement.  This is an inefficient storage."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Dmelt = pd.melt(Djoined, id_vars = filter(lambda x:not re.match(\"^\\d*$\",str(x)),Djoined.columns.tolist()), \n",
      "                 value_vars =  filter(lambda x:re.match(\"^\\d*$\",str(x)),Djoined.columns.tolist()),\n",
      "                 var_name = \"day\",\n",
      "                 value_name = \"temperature\")\n",
      "Dmelt.drop([\"country\"],axis=1,inplace=True)\n",
      "Dmelt=Dmelt[Dmelt.longitude < 0]\n",
      "Dmelt.shape\n",
      "Dmelt['quarter'] = [\"Q\" + str(int(math.floor(x/92.)+1)) for x in Dmelt.day]\n",
      "Dmelt = Dmelt[[not x for x in np.isnan(Dmelt.temperature)]]\n",
      "Dmelt.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We create a sampling backend so we can see 1000 points at a time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "backend = Backend.Sampling_DF_Backend(Dmelt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now create a dashboard that will show a lat/lon scatter of measurements, a pie chart of states, plotting of temperature by day of year, and some basic histograms.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "db = Dashboard(backend,\n",
      "    [\n",
      "        Dimension(\"longitude\",\"latitude\"),\n",
      "        Dimension(\"day\",\"temperature\",name_override=\"daytemp\"),\n",
      "        Dimension(\"temperature\",name_override=\"temp\").\n",
      "            add_group(\"rounded\",Group(\"function(d){return Math.floor(d);}\").reduce_count()),\n",
      "        Dimension(\"day\").\n",
      "            add_group(\"rounded\",Group(\"function(d){return Math.floor(d/10)*10.;}\").reduce_count()),\n",
      "        Dimension(\"year\").\n",
      "            add_group(\"rounded\",Group(\"function(d){return Math.floor(d/5)*5.;}\").reduce_count()),\n",
      "        Dimension(\"state\"),\n",
      "        Dimension(\"quarter\")\n",
      "    ],\n",
      "    [\n",
      "        Layer(height = 400),\n",
      "        Plot(\"scatter\").data_source(\"longitude_latitude\").title(\"Map\").width(700).\n",
      "            config(\"domain\",[-170,-60]).config(\"range\",[15,70]),\n",
      "        Plot(\"pie\").data_source(\"state\").title(\"State\").width(300),\n",
      "        Layer(height = 300),\n",
      "        Plot(\"scatter\").data_source(\"daytemp\").title(\"Temperature by Day of Year\").width(700).\n",
      "            config(\"domain\",[0,365]).config(\"range\",[-50,50]),\n",
      "        Plot(\"bar\").data_source(\"temp\",\"rounded\").title(\"Temperature Histgoram\").width(300).\n",
      "            config(\"domain\",[-50,50]),\n",
      "        Layer(height = 300),\n",
      "        Plot(\"bar\").data_source(\"year\",\"rounded\").title(\"Volume by Year\").width(350).\n",
      "            config(\"domain\",[1890,2014]),\n",
      "        Plot(\"bar\").data_source(\"day\",\"rounded\").title(\"Volume by Day\").width(350).\n",
      "            config(\"domain\",[0,365]),\n",
      "        Plot(\"pie\").data_source(\"quarter\").title(\"Volume by Quarter\").width(300)\n",
      "    ]\n",
      ")\n",
      "db.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}